\documentclass[preprint]{sigplanconf}

\usepackage{amsmath}
\usepackage{amssymb}

\begin{document}
\input{definitions.tex}


%%%
%%% ACM SIGPLAN class cruft
%%%

\special{papersize=8.5in,11in}
\setlength{\pdfpageheight}{\paperheight}
\setlength{\pdfpagewidth}{\paperwidth}

\conferenceinfo{CoqPL '17}{2017, Paris, France}
\copyrightyear{2017}
\copyrightdata{978-1-nnnn-nnnn-n/yy/mm}
\copyrightdoi{nnnnnnn.nnnnnnn}

%\titlebanner{banner above paper title}        % These are ignored unless
\preprintfooter{Predicate Monads}   % 'preprint' option specified.


%%%
%%% Title and Author Info
%%%

%\title{Predicate Monads: A Verification Tool for Monadic Programs}

\title{Predicate Monads:}
\subtitle{A Framework for Proving Generic Properties of Monadic Programs via Rewriting}

\authorinfo{Edwin Westbrook}
           {Galois Inc.}
           {westbrook@galois.com}
\authorinfo{Gregory Malecha}
           {UCSD}
           {gmalecha@gmail.com}

\maketitle

% \begin{abstract}
% This is the text of the abstract.
% \end{abstract}


% \category{CR-number}{subcategory}{third-level}

% % general terms are not compulsory anymore,
% % you may leave them out
% \terms
% term1, term2

% \keywords
% keyword1, keyword2


%%%
%%% Section: Introduction
%%%

\section{Introduction}

% \begin{itemize}
% \item Monads are a great way to structure programs
% \item Monad laws are great for proving equalities, but not arbitrary properties
% \item Set monad construction, with its operations
% \item Generalizing that to pairs of a monad and predicate monad for that monad
% \item Example: Hoare logic
% \end{itemize}

Monads are a simple, elegant, and powerful way to specify effectful programs.
They provide a compositional framework for building program specifications that
supports a wide variety of different sorts of effects, including mutable state,
continuations, errors and exceptions, non-determinism, and many more
\cite{moggi91}.  These effects are defined in a given monad $M$ by exposing a
set of \emph{monadic operations} to implement these effects in $M$. For
instance, if $M$ supports mutable state it often exposes it through the
following type signature:
\[
\begin{array}{lcl}
  \returnM & :: & \forall A. A \to M\;A \\
  (\bind) & :: & \forall A. \forall B. M\;A \to (A\to M\;B) \to M\;B \\
  \getM & :: & M\;S \\
  \putM & :: & S \to M\;\unit
\end{array}
\]
The first two of these, $\returnM$ and $\bind$, are the usual monad operations,
for building pure computations and for sequencing two computations together,
while $\getM$ and $\putM$ define operations for reading and writing,
respectively, the current value of the mutable state of type $S$. Note that
we also use the standard abbreviation
\[
m_1 \bindU m_2 \triangleq m_1 \bind \lamabs{x:\unit}{m_2}
\]
to sequecne a computation $m_1$ followed by a computation $m_2$ that does not
inspect the return value of $m_1$.


Each monad also comes with a set of reasoning principles, called generally the
\emph{monad laws}, for reasoning about programs written in that monad. These
monad laws take the form of a set of equalities on programs. For instance, in
addition to the standard monad laws for $\returnM$ and $\bind$, a monad that
supports mutable state will generally satisfy the following \emph{state monad
  laws}, stating that $\getM$ and $\putM$ behave as expected:
\[
\begin{array}{lcl}
  \putM\;s \bindU \putM\;s' & \lreq & \putM\;s'\\
  \putM\;s \bind \getM & \lreq & \putM\;s \bindU \returnM\;s \\
  \getM\bind\putM & \lreq & \returnM\;\Tt \\
  \getM\bind \lamabsnot{s}{\getM\bind f\;s} & \lreq & \getM\bind\lamabsnot{s}{f\;s\;s}
\end{array}
\]
The notation $\lreq$ denotes the equality relation for the monad $M$, which may
or may not correspond with the built-in equality of the meta-logic (i.e., with
intensional equality in Coq); we assume every type comes equipped with a
pre-order, which we formalize in Coq with a type class, and we write $\lrleq$
for this pre-order and $(\lreq)\triangleq(\lrleq)\cap(\lrleq)^{-1}$ as the
equivalence relation derived from $\lrleq$. Technically speaking, we formalize
monads as functors over types plus orders, and the versions of the monad laws
in our formulation include monotonicity constraints, i.e., they require that
the various components be $\mathsf{Proper}$, but we ignore this detail here
for space reasons.


A monad that supports multiple effects will additionally include monad laws for
how those effects interact; e.g., a monad with mutable state and errors might
include the law
\[
\putM\;s \bindU \fail \lreq \fail
\]
to indicate that a failure eradicates all mutable state modifications.  A
similar monad with these effects, however, might not satisfy this law, if, for
instance, failures can be recovered from.


Monad laws are a powerful tool that can be used to prove a wide variety of
properties of effectful programs, by using them as rewrite rules. For instance,
Gibbons and Hinze use this approach to verify that a number of effectful
programs have the same behavior as their corresponding functional specifications
\cite{gibbons11}.
%
The key difficulty comes when we want to prove properties other than equalities.
Monad laws cannot, for instance, prove that a function satisfies a given pre-
and post-condition, because this is not a property that can be defined in terms
of equality. Although there are approaches specifically for proving pre- and
post-conditions, such as the Hoare monad \cite{nanevski08} and the Dijkstra
monad \cite{swamy13}, it is not clear that these approaches generalize to
effects other than mutable state, or to combinations of effects.
% FIXME HERE: make this stronger
It is also not clear how to derive the Hoare monad or the Dijkstra monad
structure for an arbitrary monad that does support mutable state.


In this talk, we will present ongoing work on a general framework, called
\emph{predicate monads}, for proving properties of effectful programs that
overcomes these difficulties. The goal of this approach is to leverage the power
and elegance of the monad laws, but apply them not to monadic programs
themselves but to predicates over monadic computations.  More technically, in
our approach, each monad $M$ is associated with a so-called predicate monad $P_M$
which is, intuitively, a monad of predicates on computations in $M$.
If we view $M$ as a domain-specific semantics, then $P_M$ is a
\emph{domain-specific logic}.
% FIXME: make this point better
The predicate monad $P_M$ supports predicates over all of the monadic operations
of $M$, allowing it to reason about arbitrary effects. This reasoning comes in
the form of \emph{predicate monad laws}, which allow predicates to be proved
using rewriting. Additionally, if $M$ is defined using monad transformers, a
powerful and compositional way to build monads \cite{liang95}, then $P_M$ can be
built using the same monad transformers. This allows us to derive predicate
monads for a wide variety of monads and effects in a straightforward manner.


\section{Building Predicate Monads}

To define predicate monads formally, we capture the notion as a new sort of
computational effect, the ``logic over $M$'' effect. Just as with other sorts of
effects, this means adding a number of monadic operations and a set of monad
laws for those operations. The operations for predicate monads are:
\[
\begin{array}{lcl}
  \forallP & :: & \forall A.\forall B.(A\to P_M\;B) \to P_M\;B\\
  \existsP & :: & \forall A.\forall B.(A\to P_M\;B) \to P_M\;B\\
  \existsP & :: & \forall A.P_M\;A \to P_M\;A \to P_M\;A\\
  \singleP & :: & \forall A.M\;A \to P_M\;A\\
\end{array}
\]
Intuitively, the first three operations build predicates corresponding to
universal quantification, existential quantification, and implication. Note that
conjunction and disjunction operators $\andP$ and $\orP$ can be defined from
$\forallP$ and $\existsP$, respectively.  The fourth operation, $\singleP$,
builds the singleton predicate, i.e., the least predicate containing a given
monadic computation.

Leastness here is with respect to the pre-order $\lrleq$ of $P_M$, which can be
viewed as entailment over predicates; i.e., $p_1\lrleq p_2$ means that any
computations which satisfy $p_1$ will always satisfy $p_2$. The equality $\lreq$
associated with $P_M$ thus denotes logical equivalence of two predicates, so
that $p_1\lreq p_2$ means that $p_1$ and $p_2$ hold for the same computation in
$M$. To define the notion of which computations in $M$ satisfy a predicate in
$P_M$, we define
\[
m \vDash p \triangleq \singleP\;m \vdash p
\]
to capture the notion that computation $m$ of type $M\;A$ satisfies predicate
$P$ of type $P_M\;A$.
%
The predicate monad laws are then given as follows:
\[
\begin{array}{@{}c@{}}
\begin{array}{@{}r@{\hspace{5pt}}c@{\hspace{5pt}}l@{}}
  \singleP\;(\returnM\;x) & \lreq & \returnM\;x\\
  \singleP\;(m \bind f) & \lreq
  & (\singleP\;m)\bind (\lamabsnot{x}{\singleP\;(f\;x)})
  \\ \\
  \forallP\;p & \lrleq & p\;x\\
  (\forall x. p \lrleq q\;x) & \to & p \lrleq \forallP\;q\\
  p\;x & \lrleq & \existsP\;p\\
  (\forall x. p\;x \lrleq q) & \to & \existsP\;p \lrleq q\\
  \andP\;p_1\;p_2 \lrleq p_3 & \leftrightarrow & p_1 \lrleq \impliesP\;p_2\;p_3
\end{array}
  \\ \\
\begin{array}{@{}r@{\hspace{5pt}}c@{\hspace{5pt}}l@{}}
  (\forall x.\forall y. x\lrleq y \to p\;x \lrleq q\;x)
  & \to & \forallP\;p \lrleq \forallP\;q\\
  (\forall x.\forall y. x\lrleq y \to p\;x \lrleq q\;x)
  & \to & \existsP\;p \lrleq \existsP\;q
\end{array}
  \\
  (p_1'\lrleq p_1 \wedge p_2\lrleq p_2') \to
  \impliesP\;p_1\;p_2 \lrleq \impliesP\;p_1'\;p_2'
\end{array}
\]
The first two laws state that applying $\singleP$ to a monadic operation in $M$
always yields an application of the same monadic operation in $P_M$. That is,
$\returnM\;x$ in $P_M$ builds a predicate for recognizing the computation
$\returnM\;x$ in $M$, while $P\bind q$ in $P_M$ builds a predicate for
recognizing computations that are equivalent to $m\bind f$ in $M$ for some
$M\vDash P$ and some $f$ such that $\forall x.f x \vDash P x$.
%
The second set of laws state that $\forallP$, $\existsP$, and $\impliesP$
satisfy usual introduction and elimination rules for the corresponding
connectives in first-order logic. Note that, viewed differently, the laws for
$\forallP$ and $\existsP$ state that $\lrleq$ is a complete lattice, while the
law for $\impliesP$ states that $\lrleq$ is a Heyting algebra.
%
Finally, the third set of rules express monotonicity constraints, also known in
Coq as $\mathsf{Proper}$ constraints, on the predicate monad operators.

In order to build predicate monads with this structure, we start by defining the
predicate monad $P_{\mathsf{Identity}}$ for the simplest possible monad, the
$\mathsf{Identity}$ monad. It turns out that the $\mathsf{Set}$ monad, defined as
$\mathsf{Set}\;A\triangleq\;A\to\Prop$ has the desired structure, by defining
$\forallP$, $\existsP$, and $\impliesP$ to be the straightforward application of
the corresponding combinators in $\Prop$, and by defining
\[
p \lrleq q \triangleq \forall x. p\;x \to \exists y. x\lrleq y \wedge q\;y
\]
meaning that entailment in the $\mathsf{Set}$ predicate monad corresponds to
a ``covering'' property, where each element of the lesser set has a greater
element in the greater set.
%
It also turns out that, for many standard monad transformers $\mathcal{T}$, we
can define $P_{\mathcal{T}(M)}\triangleq\mathcal{T}(P_M)$, though, again, we
omit the details here. This means that, we can build up predicate monads for a
wide variety of different sorts of effects, using the same ``transformer stack''
used to build the underlying monad.


\section{Proving Properties using Predicate Monads}

As discussed above, predicate monads come equipped with the standard
introduction and elimination rules for logical connectives, the real power
comes from what we can prove just with rewriting.


FIXME HERE: define HoareP in predicate monads

FIXME HERE: briefly explain how rewriting will prove it for a given computation



\bibliographystyle{abbrvnat}
\bibliography{bib}

\end{document}
